{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This is a practice Artificial Neural Network\n",
    "# The problem being solved is based off of a model bank with fake data\n",
    "# The bank has customers that have left for whatever reason\n",
    "# The goal is to find why these customers have left using information such as account balance and gender\n",
    "# The last column of the data states whether or not the customer has left the bank\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np #Math operations library\n",
    "import matplotlib.pyplot as plt #Visualization library\n",
    "import pandas as pd #Matrix handler\n",
    "\n",
    "import keras # Brings in tensorflow with it\n",
    "from keras.models import Sequential # Used for initialization of ANN\n",
    "from keras.layers import Dense, Dropout# adds layers to ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier # ability to turn network into a function definition\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler #Methods to change categorical strings to numbers and scaling ability\n",
    "\n",
    "parameters = {'batch_size': 16, # 50 epochs, 264 nodes, 3 hidden layers\n",
    "              'epochs': 100,\n",
    "              'learning_rate': 0.00001,\n",
    "              'nodes': 264,\n",
    "              'hidden_layers': 3,\n",
    "              'dropout': 0.5\n",
    "             } # Creates list of parameters to test to find most successful one\n",
    "parameters['optimizer'] = Adam(parameters['learning_rate'])\n",
    "\n",
    "class data_handler:\n",
    "    def __init__(self, pkl_location, sc):\n",
    "        data = pd.read_pickle(pkl_location)\n",
    "        data = data.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        x = data[list(range(0, 264))]# max 264 x columns\n",
    "        x = sc.fit_transform(x)\n",
    "        self.x = pd.DataFrame(x)\n",
    "        \n",
    "        self.y = data[['Rest', 'Emote', 'Solve']]\n",
    "        del data\n",
    "        \n",
    "        self.tenth = math.floor(self.x.shape[0] / 10)\n",
    "        \n",
    "    def get_cross_val(self, iteration):\n",
    "        if iteration > 10:\n",
    "            raise ValueError('Crossval Iteration Exceeds 10')\n",
    "        \n",
    "        iteration = iteration - 1\n",
    "        train_array = list(range(0, iteration*self.tenth)) + list(range((iteration+1)*self.tenth, self.x.shape[0]))\n",
    "        test_array = list(range(iteration*self.tenth, (iteration+1)*self.tenth))\n",
    "        \n",
    "        x_train = self.x.iloc[train_array].values\n",
    "        y_train = self.y.iloc[train_array].values\n",
    "        x_test = self.x.iloc[test_array].values\n",
    "        y_test = self.y.iloc[test_array].values\n",
    "        \n",
    "        return x_train, y_train, x_test, y_test\n",
    "\n",
    "def build_classifier(parameters):\n",
    "    classifier = Sequential() # This is the ANN object\n",
    "    classifier.add(Dense(input_dim=264, units=parameters['nodes'], kernel_initializer='uniform', activation='relu'))\n",
    "    classifier.add(Dropout(rate=parameters['dropout']))\n",
    "    \n",
    "    for layer in range(0, parameters['hidden_layers']):\n",
    "        classifier.add(Dense(units=parameters['nodes'], kernel_initializer='uniform', activation='relu')) #Creates first hidden layer\n",
    "        classifier.add(Dropout(rate=parameters['dropout']))\n",
    "        \n",
    "    classifier.add(Dense(units=3, kernel_initializer='uniform', activation='softmax')) # Output layer. Only 1 ouput category, sigmoid activation to get probability of sureness\n",
    "    # Note: Softmax applies to a dependent variable that has more than 2 categories\n",
    "    # i.e. fMRI categorizations\n",
    "    \n",
    "    classifier.compile(loss='categorical_crossentropy',\n",
    "              optimizer=parameters['optimizer'],\n",
    "              metrics=['accuracy'])\n",
    "    # Notes\n",
    "    # adam is a kind of stochastic gradient descent\n",
    "    # For multivariabel, use categorical cross entropy\n",
    "    # Accuracy is predefined\n",
    "    return classifier\n",
    "# Creates a standard Keras type classifier composed of the defined network for\n",
    "# k-means testing\n",
    "data = data_handler('./atlas.pkl', StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 207847 samples, validate on 207847 samples\n",
      "Epoch 1/100\n",
      "207847/207847 [==============================] - 48s 232us/step - loss: 0.8546 - acc: 0.5981 - val_loss: 0.8061 - val_acc: 0.5990\n",
      "Epoch 2/100\n",
      "207847/207847 [==============================] - 49s 237us/step - loss: 0.8053 - acc: 0.6017 - val_loss: 0.8051 - val_acc: 0.5993\n",
      "Epoch 3/100\n",
      "207847/207847 [==============================] - 49s 234us/step - loss: 0.8043 - acc: 0.6018 - val_loss: 0.8044 - val_acc: 0.5993\n",
      "Epoch 4/100\n",
      "207847/207847 [==============================] - 50s 240us/step - loss: 0.8032 - acc: 0.6018 - val_loss: 0.8028 - val_acc: 0.5992\n",
      "Epoch 5/100\n",
      "207847/207847 [==============================] - 49s 237us/step - loss: 0.8010 - acc: 0.6028 - val_loss: 0.7986 - val_acc: 0.6022\n",
      "Epoch 6/100\n",
      "207847/207847 [==============================] - 50s 242us/step - loss: 0.7948 - acc: 0.6129 - val_loss: 0.7885 - val_acc: 0.6201\n",
      "Epoch 7/100\n",
      "207847/207847 [==============================] - 51s 244us/step - loss: 0.7863 - acc: 0.6274 - val_loss: 0.7780 - val_acc: 0.6343\n",
      "Epoch 8/100\n",
      "207847/207847 [==============================] - 51s 245us/step - loss: 0.7764 - acc: 0.6391 - val_loss: 0.7653 - val_acc: 0.6470\n",
      "Epoch 9/100\n",
      "207847/207847 [==============================] - 51s 244us/step - loss: 0.7663 - acc: 0.6469 - val_loss: 0.7525 - val_acc: 0.6565\n",
      "Epoch 10/100\n",
      "207847/207847 [==============================] - 50s 239us/step - loss: 0.7559 - acc: 0.6544 - val_loss: 0.7406 - val_acc: 0.6635\n",
      "Epoch 11/100\n",
      "124096/207847 [================>.............] - ETA: 16s - loss: 0.7468 - acc: 0.6606"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(0, 10):\n",
    "    i = i + 1\n",
    "    #train\n",
    "    tensorboard = TensorBoard(log_dir=\"../logs/{}\".format(time.time()))\n",
    "    x_train, y_train, x_test, y_test = data.get_cross_val(i)\n",
    "    classifier = build_classifier(parameters)\n",
    "    classifier.fit(x_train, y_train, batch_size=parameters['batch_size'], epochs=parameters['epochs'],callbacks=[tensorboard], validation_split=0.5)\n",
    "    \n",
    "    #test\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    y_pred = pd.DataFrame(y_pred)\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "    print(y_test)\n",
    "    y_pred['test_0'] = y_test.iloc[:, [0]]\n",
    "    y_pred['test_1'] = y_test.iloc[:, [1]]\n",
    "    y_pred['test_2'] = y_test.iloc[:, [2]]\n",
    "    \n",
    "    y_pred.to_pickle('./Cross_Validation_Results/cv_results_' + str(i - 1) + '.pkl')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
